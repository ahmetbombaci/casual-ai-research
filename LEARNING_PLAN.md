# Causal AI Learning Plan: 2 Hours Daily

_A Practical, Structured 12-Week Journey from Basics to Mastery_

## ðŸ“‹ Quick Overview

**Duration:** 12 weeks (84 days)  
**Daily Commitment:** 2 hours  
**Total Time:** ~168 hours  
**Schedule:** 6 days/week + 1 review day

### â° Your Daily 2-Hour Block

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 0:00-0:15  Warm-up & Review         â”‚
â”‚ 0:15-0:45  Theory & Concepts        â”‚
â”‚ 0:45-1:45  Hands-on Practice        â”‚
â”‚ 1:45-2:00  Reflection & Planning    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸŽ¯ Pre-Learning Setup

### Technical Requirements

```bash
# Create your learning environment
conda create -n causal-ai python=3.9
conda activate causal-ai

# Core installations (Week 0)
pip install notebook jupyterlab
pip install numpy pandas matplotlib seaborn
pip install scikit-learn statsmodels

# Causal libraries (install as needed)
pip install dowhy  # Week 1
pip install econml  # Week 5
pip install causalml  # Week 6
pip install causal-learn  # Week 8
```

### Workspace Organization

```
causal-ai-journey/
â”œâ”€â”€ ðŸ“š resources/
â”‚   â”œâ”€â”€ books/
â”‚   â”œâ”€â”€ papers/
â”‚   â””â”€â”€ cheatsheets/
â”œâ”€â”€ ðŸ“ notes/
â”‚   â”œâ”€â”€ daily-logs/
â”‚   â”œâ”€â”€ concepts/
â”‚   â””â”€â”€ questions.md
â”œâ”€â”€ ðŸ’» code/
â”‚   â”œâ”€â”€ week-01/
â”‚   â”œâ”€â”€ week-02/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ ðŸš€ projects/
â”‚   â”œâ”€â”€ mini-projects/
â”‚   â””â”€â”€ portfolio/
â””â”€â”€ ðŸ“Š progress/
    â”œâ”€â”€ tracker.xlsx
    â””â”€â”€ reflections.md
```

### Learning Tools Setup

1. **Note-taking:** Obsidian or Notion for concept maps
2. **Code:** VSCode with Python & Jupyter extensions
3. **Version Control:** Git repository for all work
4. **Time Tracking:** Toggl or simple spreadsheet
5. **Community:** Join PyWhy Discord & r/CausalInference

---

## ðŸ“… Phase 1: Foundations (Weeks 1-3)

_Building Causal Intuition_

### ðŸ—“ï¸ Week 1: From Correlation to Causation

#### **Day 1 (Monday): The Causality Mindset**

**ðŸŽ¯ Learning Objectives:**

- Distinguish correlation from causation
- Identify real-world confounding examples
- Understand Simpson's Paradox

**ðŸ“š Theory (30 min):**

1. Read: Brady Neal Ch. 1 Introduction (pages 1-10)
2. Watch: [Judea Pearl - The Book of Why Talk](https://www.youtube.com/watch?v=ZaPV1OSEpHw) (first 15 min)

**ðŸ’» Practice (60 min):**

```python
# Exercise 1: Simpson's Paradox Visualization
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load Berkeley admissions data
# URL: https://raw.githubusercontent.com/wadefagen/datasets/master/berkeley-admissions/data.csv
data = pd.read_csv('berkeley_admissions.csv')

# Task 1: Show overall admission rates by gender
# Task 2: Show department-specific rates
# Task 3: Explain the paradox

# Your code here...
```

**ðŸ“Š Mini-Challenge:**
Find 3 examples of correlation â‰  causation in news headlines today

**âœï¸ Reflection Questions:**

1. Why is causal inference hard?
2. What confounders exist in my domain?
3. How would I explain Simpson's Paradox to a colleague?

**ðŸ“ Deliverable:**
Create a notebook demonstrating Simpson's Paradox with visualizations

---

#### **Day 2 (Tuesday): Introduction to DAGs**

**ðŸŽ¯ Learning Objectives:**

- Draw causal diagrams
- Identify causal paths
- Use NetworkX for DAG visualization

**ðŸ“š Theory (30 min):**

1. Read: Pearl's "Causal Inference in Statistics" - Chapter 1
2. Study: DAG notation and terminology

**ðŸ’» Practice (60 min):**

```python
# Exercise 2: Your First DAGs
import networkx as nx
import matplotlib.pyplot as plt
from dowhy import gcm

# Create DAGs for these scenarios:
# 1. Ice cream sales â†’ Swimming pool drownings (with temperature as confounder)
# 2. Education â†’ Income (with ability as confounder)
# 3. Smoking â†’ Lung cancer (with genetics as confounder)

def create_and_visualize_dag(edges, title):
    G = nx.DiGraph()
    G.add_edges_from(edges)

    pos = nx.spring_layout(G)
    plt.figure(figsize=(8, 6))
    nx.draw(G, pos, with_labels=True,
            node_color='lightblue',
            node_size=1500,
            font_size=10,
            arrows=True)
    plt.title(title)
    return G

# Example:
edges = [('Temperature', 'Ice_Cream_Sales'),
         ('Temperature', 'Drownings')]
dag1 = create_and_visualize_dag(edges, 'Ice Cream and Drownings')
```

**ðŸ“Š Mini-Challenge:**
Draw DAG for: "Does working from home increase productivity?"

**âœï¸ Reflection:**

- What makes a good causal diagram?
- How do I know if my DAG is complete?

---

#### **Day 3 (Wednesday): Confounders, Mediators, and Colliders**

**ðŸŽ¯ Learning Objectives:**

- Identify three basic DAG patterns
- Understand when to control for variables
- Recognize collider bias

**ðŸ“š Theory (30 min):**

1. Read: Brady Neal Ch. 2 - "Graphical Causal Models"
2. Watch: "Confounders, Mediators, and Colliders" video

**ðŸ’» Practice (60 min):**

```python
# Exercise 3: Identifying Causal Patterns
import numpy as np
import pandas as pd

# Generate data for each pattern
np.random.seed(42)
n = 1000

# Pattern 1: Confounder
# Z â†’ X, Z â†’ Y, X â†’ Y
Z = np.random.normal(0, 1, n)  # Confounder
X = 2 * Z + np.random.normal(0, 1, n)  # Treatment
Y = 3 * X + 2 * Z + np.random.normal(0, 1, n)  # Outcome

df_confound = pd.DataFrame({'X': X, 'Y': Y, 'Z': Z})

# Task: Show spurious correlation without controlling for Z
# Then show true effect after controlling

# Pattern 2: Mediator
# X â†’ M â†’ Y
X = np.random.normal(0, 1, n)
M = 2 * X + np.random.normal(0, 1, n)  # Mediator
Y = 3 * M + np.random.normal(0, 1, n)

# Task: Show total effect vs direct effect

# Pattern 3: Collider
# X â†’ Z â† Y
X = np.random.normal(0, 1, n)
Y = np.random.normal(0, 1, n)
Z = X + Y + np.random.normal(0, 0.1, n)  # Collider

# Task: Show no correlation between X and Y
# Then show spurious correlation when conditioning on Z
```

**ðŸ“Š Mini-Challenge:**
Find example of collider bias in real research (hint: survivorship bias)

---

#### **Day 4 (Thursday): The Backdoor Criterion**

**ðŸŽ¯ Learning Objectives:**

- Apply backdoor criterion
- Find adjustment sets
- Use DoWhy for identification

**ðŸ“š Theory (30 min):**

1. Read: Brady Neal Ch. 2 - "Backdoor Criterion"
2. Understand: Blocking backdoor paths

**ðŸ’» Practice (60 min):**

```python
# Exercise 4: Finding Adjustment Sets
from dowhy import CausalModel

# Complex DAG scenario
causal_graph = """
    digraph {
        U1[label="Unobserved"];
        U2[label="Unobserved"];

        Age -> Income;
        Age -> Health;
        Education -> Income;
        Exercise -> Health;
        Income -> Health;
        Genetics -> Health;
        Genetics -> Exercise;
        U1 -> Income;
        U1 -> Health;
        U2 -> Exercise;
        U2 -> Health;
    }
"""

# Task 1: Find all backdoor paths from Exercise to Health
# Task 2: Identify minimal adjustment set
# Task 3: Use DoWhy to verify

model = CausalModel(
    data=your_data,
    treatment='Exercise',
    outcome='Health',
    graph=causal_graph
)

# Identify effect
identified = model.identify_effect()
print(identified)
```

---

#### **Day 5 (Friday): d-Separation and Independence**

**ðŸŽ¯ Learning Objectives:**

- Master d-separation rules
- Test conditional independence
- Connect graphs to probability

**ðŸ“š Theory (30 min):**

1. Read: "d-separation without tears"
2. Practice: d-separation exercises

**ðŸ’» Practice (60 min):**

```python
# Exercise 5: d-Separation Testing
from causallearn.utils.cit import fisherz
from causallearn.utils.GraphUtils import GraphUtils

# Create test data
def test_dseparation(dag, data, X, Y, Z_set):
    """
    Test if X and Y are d-separated given Z_set
    """
    # Statistical independence test
    p_value = fisherz(data, X, Y, Z_set)

    # Graph-based d-separation check
    is_dsep = dag.is_dseparated(X, Y, Z_set)

    return {
        'statistical_independent': p_value > 0.05,
        'graphically_dseparated': is_dsep,
        'p_value': p_value
    }

# Test cases:
# 1. Chain: A â†’ B â†’ C (A âŠ¥ C | B?)
# 2. Fork: A â† B â†’ C (A âŠ¥ C | B?)
# 3. Collider: A â†’ B â† C (A âŠ¥ C | B?)
```

---

#### **Day 6 (Saturday): Week 1 Review & Integration**

**ðŸŽ¯ Objectives:**

- Consolidate week's learning
- Complete mini-project
- Plan Week 2

**ðŸ“š Review (30 min):**

- Revisit key concepts
- Review your notes
- List questions

**ðŸ’» Mini-Project (90 min):**

**Project: "Causal Analysis of Employee Satisfaction"**

Dataset: HR Analytics (simulated or Kaggle)

Tasks:

1. Draw complete causal diagram
2. Identify all confounders for: Training â†’ Performance
3. Show Simpson's Paradox in the data
4. Test d-separation assumptions
5. Find valid adjustment sets
6. Create presentation notebook

**Deliverable Structure:**

```markdown
# Employee Satisfaction Causal Analysis

## 1. Business Problem

[Define the causal question]

## 2. Causal Model

[Draw and justify your DAG]

## 3. Confounding Analysis

[Identify and explain confounders]

## 4. Statistical Tests

[Show correlations vs causal effects]

## 5. Recommendations

[What interventions would you suggest?]
```

---

### ðŸ—“ï¸ Week 2: Causal Models and Interventions

#### **Day 7 (Monday): Structural Causal Models**

**ðŸŽ¯ Learning Objectives:**

- Define SCMs mathematically
- Simulate data from SCMs
- Understand structural equations

**ðŸ“š Theory (30 min):**

1. Read: Brady Neal Ch. 3 - "The Flow of Association and Causation"
2. Study: SCM = {Variables, Equations, Noise}

**ðŸ’» Practice (60 min):**

```python
# Exercise 6: Building Your First SCM
class StructuralCausalModel:
    def __init__(self, equations, noise_models):
        self.equations = equations
        self.noise_models = noise_models

    def generate_data(self, n_samples=1000):
        # Generate noise
        noise = {var: model(n_samples)
                for var, model in self.noise_models.items()}

        # Compute variables using structural equations
        data = {}
        # Topological ordering important!

        return pd.DataFrame(data)

    def intervene(self, do_dict):
        # Modify equations based on intervention
        pass

# Example: Job Market SCM
def create_job_market_scm():
    equations = {
        'ability': lambda n: n['u_ability'],
        'education': lambda n: 0.7 * data['ability'] + n['u_education'],
        'job_quality': lambda n: 0.5 * data['education'] + 0.3 * data['ability'] + n['u_job'],
        'income': lambda n: 1000 * data['job_quality'] + 500 * data['education'] + n['u_income']
    }

    noise_models = {
        'u_ability': lambda n: np.random.normal(0, 1, n),
        'u_education': lambda n: np.random.normal(0, 0.5, n),
        'u_job': lambda n: np.random.normal(0, 0.3, n),
        'u_income': lambda n: np.random.normal(0, 200, n)
    }

    return StructuralCausalModel(equations, noise_models)
```

---

#### **Day 8 (Tuesday): Interventions and do-operator**

**ðŸŽ¯ Learning Objectives:**

- Distinguish P(Y|X) from P(Y|do(X))
- Perform graph surgery
- Simulate interventions

**ðŸ“š Theory (30 min):**

1. Read: "The do-operator explained"
2. Understand: Why conditioning â‰  intervening

**ðŸ’» Practice (60 min):**

```python
# Exercise 7: Interventions vs Observations
import dowhy.gcm as gcm

# Build causal model
causal_model = gcm.StructuralCausalModel(graph)

# Observational: P(Y|X=x)
observational = data[data['X'] == x]['Y'].mean()

# Interventional: P(Y|do(X=x))
# Method 1: Graph surgery
def graph_surgery(scm, intervention):
    modified_scm = scm.copy()
    # Remove incoming edges to intervened variables
    # Set variable to intervention value
    return modified_scm

# Method 2: Using DoWhy
samples = gcm.interventional_samples(
    causal_model,
    interventions={'X': lambda: x},
    num_samples=1000
)
interventional = samples['Y'].mean()

print(f"P(Y|X={x}): {observational}")
print(f"P(Y|do(X={x})): {interventional}")
print(f"Confounding bias: {observational - interventional}")
```

---

#### **Day 9 (Wednesday): Introduction to do-calculus**

**ðŸŽ¯ Learning Objectives:**

- Understand three rules of do-calculus
- Apply rules to simple graphs
- Check identifiability

**ðŸ“š Theory (30 min):**

1. Read: Pearl's do-calculus rules
2. Study: When causal effects are identifiable

**ðŸ’» Practice (60 min):**

```python
# Exercise 8: Applying do-calculus Rules
from dowhy.causal_identifier import CausalIdentifier

# Rule 1: Insertion/deletion of observations
# P(Y|do(X), Z, W) = P(Y|do(X), W) if Y âŠ¥ Z | X, W in G_XÌ…

# Rule 2: Action/observation exchange
# P(Y|do(X), do(Z), W) = P(Y|do(X), Z, W) if Y âŠ¥ Z | X, W in G_XÌ…ZÌ²

# Rule 3: Insertion/deletion of actions
# P(Y|do(X), do(Z), W) = P(Y|do(X), W) if Y âŠ¥ Z | X, W in G_XÌ…Z(W)

def check_identifiability(graph, treatment, outcome):
    """
    Check if causal effect is identifiable
    """
    model = CausalModel(graph=graph)
    identifier = CausalIdentifier(model, treatment, outcome)

    try:
        estimand = identifier.identify_effect()
        return True, estimand
    except:
        return False, None

# Test on various graphs
graphs = {
    'confounded': "Xâ†Zâ†’Y, Xâ†’Y",
    'instrumental': "Zâ†’Xâ†’Y, Uâ†’X, Uâ†’Y",
    'frontdoor': "Xâ†’Mâ†’Y, Uâ†’X, Uâ†’Y"
}

for name, graph in graphs.items():
    identifiable, estimand = check_identifiability(graph, 'X', 'Y')
    print(f"{name}: Identifiable = {identifiable}")
    if identifiable:
        print(f"Estimand: {estimand}")
```

---

#### **Day 10 (Thursday): Front-door Criterion**

**ðŸŽ¯ Learning Objectives:**

- Apply front-door adjustment
- Understand when it's needed
- Compare with backdoor

**ðŸ“š Theory (30 min):**

1. Read: Front-door criterion explanation
2. Study: Classic smoking â†’ cancer example

**ðŸ’» Practice (60 min):**

```python
# Exercise 9: Front-door Adjustment Implementation
def frontdoor_adjustment(data, X, M, Y):
    """
    Implement front-door adjustment
    P(Y|do(X)) = Î£â‚˜P(M=m|X)Î£â‚“P(Y|M=m,X=x)P(X=x)
    """
    # Step 1: P(M|X)
    p_m_given_x = data.groupby([X, M]).size() / data.groupby(X).size()

    # Step 2: P(Y|M,X)
    p_y_given_mx = data.groupby([M, X])[Y].mean()

    # Step 3: P(X)
    p_x = data[X].value_counts(normalize=True)

    # Combine
    effect = 0
    for m_val in data[M].unique():
        for x_val in data[X].unique():
            effect += (p_m_given_x[1, m_val] - p_m_given_x[0, m_val]) * \
                     p_y_given_mx[m_val, x_val] * p_x[x_val]

    return effect

# Simulate smoking â†’ tar â†’ cancer with hidden confounder
np.random.seed(42)
n = 10000

# Hidden confounder (genetics)
genetics = np.random.binomial(1, 0.3, n)

# Smoking (affected by genetics)
smoking = np.random.binomial(1, 0.2 + 0.4 * genetics, n)

# Tar deposits (mediator, only affected by smoking)
tar = np.random.binomial(1, 0.1 + 0.7 * smoking, n)

# Lung cancer (affected by tar and genetics)
cancer = np.random.binomial(1, 0.05 + 0.3 * tar + 0.2 * genetics, n)

data = pd.DataFrame({
    'smoking': smoking,
    'tar': tar,
    'cancer': cancer,
    'genetics': genetics
})

# Compare estimates
naive = data.groupby('smoking')['cancer'].mean().diff().iloc[-1]
frontdoor = frontdoor_adjustment(data, 'smoking', 'tar', 'cancer')

print(f"Naive estimate: {naive:.3f}")
print(f"Front-door estimate: {frontdoor:.3f}")
```

---

#### **Day 11 (Friday): Counterfactual Reasoning**

**ðŸŽ¯ Learning Objectives:**

- Compute counterfactuals from SCMs
- Understand three steps: Abduction, Action, Prediction
- Apply to real scenarios

**ðŸ“š Theory (30 min):**

1. Read: Brady Neal Ch. 4 - "Counterfactuals"
2. Study: Twin network representation

**ðŸ’» Practice (60 min):**

```python
# Exercise 10: Computing Counterfactuals
class CounterfactualSCM:
    def __init__(self, scm):
        self.scm = scm

    def compute_counterfactual(self, observed_data, intervention, target):
        """
        Three steps of counterfactual inference:
        1. Abduction: Infer noise from observed data
        2. Action: Apply intervention
        3. Prediction: Compute outcome
        """
        # Step 1: Abduction - infer noise values
        noise = self.infer_noise(observed_data)

        # Step 2: Action - modify SCM
        modified_scm = self.scm.intervene(intervention)

        # Step 3: Prediction - compute with inferred noise
        counterfactual_data = modified_scm.predict(noise)

        return counterfactual_data[target]

    def infer_noise(self, observed_data):
        # Inverse of structural equations
        pass

# Example: "What if this patient had exercised?"
patient_data = {
    'age': 45,
    'exercise': 0,  # Didn't exercise
    'diet_quality': 3,
    'health_score': 65  # Observed outcome
}

# Counterfactual query
cf_health = compute_counterfactual(
    observed_data=patient_data,
    intervention={'exercise': 1},
    target='health_score'
)

print(f"Actual health score: {patient_data['health_score']}")
print(f"Counterfactual (if exercised): {cf_health}")
print(f"Individual treatment effect: {cf_health - patient_data['health_score']}")
```

---

#### **Day 12 (Saturday): Week 2 Integration**

**ðŸ’» Week 2 Project: "Build a Complete Causal Analysis System"**

Create an end-to-end system that:

1. Takes a dataset and causal graph
2. Identifies causal effects
3. Estimates effects using multiple methods
4. Computes counterfactuals
5. Validates assumptions

```python
class CausalAnalysisSystem:
    def __init__(self, data, graph):
        self.data = data
        self.graph = graph
        self.model = CausalModel(data, graph)

    def full_analysis(self, treatment, outcome):
        results = {}

        # 1. Identification
        results['identified'] = self.identify(treatment, outcome)

        # 2. Estimation (multiple methods)
        results['estimates'] = self.estimate_all(treatment, outcome)

        # 3. Counterfactuals
        results['counterfactuals'] = self.compute_counterfactuals()

        # 4. Sensitivity analysis
        results['sensitivity'] = self.sensitivity_analysis()

        # 5. Visualization
        self.visualize_results(results)

        return results
```

---

### ðŸ—“ï¸ Week 3: Potential Outcomes & Causal Estimands

#### **Day 13-18: Detailed Daily Plans**

[Continuing with same detailed format for remaining days...]

**Day 13: Potential Outcomes Framework**

- Rubin Causal Model basics
- Fundamental problem of causal inference
- Connection to SCMs

**Day 14: Treatment Effects Zoo**

- ATE, ATT, ATC, LATE, CATE
- When to use each estimand
- Practical examples

**Day 15: Identification Assumptions**

- SUTVA, Ignorability, Positivity
- Testing assumptions
- Sensitivity analysis

**Day 16: Randomized Experiments**

- Gold standard causality
- Design considerations
- Analysis of experiments

**Day 17: Observational Studies**

- Challenges and solutions
- Covariate selection
- Diagnostic checks

**Day 18: Week 3 Project**

- Complete RCT analysis
- Compare to observational approach
- Document limitations

---

## ðŸ“… Phase 2: Core Methods (Weeks 4-6)

_Mastering Essential Techniques_

### ðŸ—“ï¸ Week 4: Matching and Weighting

#### Daily Breakdown:

- **Day 19:** Exact and coarsened matching
- **Day 20:** Propensity score estimation
- **Day 21:** Propensity score matching
- **Day 22:** Inverse probability weighting
- **Day 23:** Doubly robust methods
- **Day 24:** Week 4 Project

#### Week 4 Hands-on Project:

**"Evaluating Job Training Program"**
Using LaLonde dataset, implement:

1. Multiple matching approaches
2. Balance diagnostics
3. Sensitivity analysis
4. Comparison of estimates

### ðŸ—“ï¸ Week 5: Instrumental Variables & Natural Experiments

#### Daily Breakdown:

- **Day 25:** IV intuition and assumptions
- **Day 26:** Two-stage least squares
- **Day 27:** Weak instruments
- **Day 28:** Local Average Treatment Effect
- **Day 29:** Applications and examples
- **Day 30:** Week 5 Project

### ðŸ—“ï¸ Week 6: Difference-in-Differences & Panel Methods

#### Daily Breakdown:

- **Day 31:** DiD basics and assumptions
- **Day 32:** Parallel trends testing
- **Day 33:** Staggered adoption
- **Day 34:** Synthetic control method
- **Day 35:** Fixed effects and panel data
- **Day 36:** Week 6 Project

---

## ðŸ“… Phase 3: Advanced Methods (Weeks 7-9)

_Modern ML-Based Approaches_

### ðŸ—“ï¸ Week 7: Machine Learning for Causal Inference

#### Daily Focus Areas:

- Double/debiased machine learning
- Causal forests
- Meta-learners (S, T, X, R)
- Targeted learning
- Cross-fitting techniques
- Week project: CATE estimation

### ðŸ—“ï¸ Week 8: Causal Discovery

#### Daily Focus Areas:

- Constraint-based methods (PC, FCI)
- Score-based methods (GES, NOTEARS)
- Functional causal models
- Time series causal discovery
- Validation techniques
- Week project: Discover causal structure

### ðŸ—“ï¸ Week 9: Special Topics

#### Daily Focus Areas:

- Mediation analysis
- Time-varying treatments
- Interference and spillovers
- Missing data and causality
- Causal inference in RL
- Integration week project

---

## ðŸ“… Phase 4: Real-World Application (Weeks 10-12)

_Portfolio Development_

### ðŸ—“ï¸ Week 10: Domain-Specific Applications

Choose your domain and implement:

- Healthcare: Patient outcome prediction
- Marketing: Campaign optimization
- Policy: Program evaluation
- Tech: A/B testing enhancement
- Finance: Risk assessment

### ðŸ—“ï¸ Week 11: Comprehensive Project

Build end-to-end causal analysis:

1. Problem formulation
2. Data collection/simulation
3. Causal model specification
4. Multiple estimation approaches
5. Validation and sensitivity
6. Actionable recommendations

### ðŸ—“ï¸ Week 12: Portfolio & Community

- Create GitHub portfolio
- Write blog posts
- Contribute to open source
- Present findings
- Network building
- Plan continued learning

---

## ðŸ“Š Progress Tracking System

### Daily Check-in Template

```markdown
## Day [X] - [Date]

### âœ… Completed

- [ ] Theory reading (30 min)
- [ ] Coding exercise (60 min)
- [ ] Notes/reflection (15 min)
- [ ] Question logged

### ðŸ’¡ Key Insights

1.
2.
3.

### ðŸ¤” Questions/Struggles

-

### ðŸŽ¯ Tomorrow's Focus

-

### â±ï¸ Time Logged: **\_** hours
```

### Weekly Review Template

```markdown
## Week [X] Review

### ðŸŽ“ Concepts Mastered

- [ ]
- [ ]
- [ ]

### ðŸ’» Code Completed

- [ ] All exercises
- [ ] Mini-project
- [ ] GitHub commits

### ðŸ“ˆ Self-Assessment (1-5)

- Understanding: \_\_\_
- Implementation: \_\_\_
- Confidence: \_\_\_

### ðŸš€ Next Week Prep

-
```

### Phase Completion Checklist

#### Phase 1 âœ“

- [ ] Can draw and interpret DAGs
- [ ] Understand confounding, mediation, collision
- [ ] Can identify causal effects
- [ ] Built first causal model
- [ ] Completed 3 mini-projects

#### Phase 2 âœ“

- [ ] Implemented propensity score methods
- [ ] Applied instrumental variables
- [ ] Used difference-in-differences
- [ ] Understand assumptions and limitations
- [ ] Completed method comparison project

#### Phase 3 âœ“

- [ ] Applied ML to causal inference
- [ ] Discovered causal structure from data
- [ ] Handled complex scenarios
- [ ] Built reusable code library
- [ ] Completed advanced project

#### Phase 4 âœ“

- [ ] Solved real-world problem
- [ ] Created portfolio pieces
- [ ] Wrote technical blog posts
- [ ] Connected with community
- [ ] Have job-ready skills

---

## ðŸ’ª Overcoming Common Challenges

### Challenge 1: "The Math is Too Hard"

**Solutions:**

- Start with intuition, then formalize
- Use simulations to understand
- Find visual explanations
- Join study groups
- Accept gradual understanding

### Challenge 2: "I Don't Have Real Data"

**Solutions:**

- Use simulation (you control ground truth!)
- Kaggle datasets
- UCI repository
- Generate synthetic data
- Public government data

### Challenge 3: "Too Many Methods to Learn"

**Solutions:**

- Master one method deeply first
- Understand when each applies
- Build personal cheat sheet
- Focus on your domain's common methods

### Challenge 4: "Can't Find Time"

**Solutions:**

- Morning routine before work
- Lunch break theory reading
- Weekend project time
- Reduce to 1 hour but stay consistent
- Track time to find gaps

### Challenge 5: "Feeling Overwhelmed"

**Solutions:**

- Review fundamentals
- Take breaks when needed
- Celebrate small wins
- Connect with others learning
- Remember: confusion is part of learning

---

## ðŸ› ï¸ Practical Resources

### Essential Bookmarks

#### Documentation

- [DoWhy Docs](https://py-why.github.io/dowhy/)
- [EconML Docs](https://econml.azurewebsites.net/)
- [CausalML Docs](https://causalml.readthedocs.io/)

#### Tutorials

- [Causal Inference for The Brave and True](https://matheusfacure.github.io/python-causality-handbook/landing-page.html)
- [Mixtape Sessions](https://mixtape.scunning.com/)

#### Communities

- [PyWhy Discord](https://discord.gg/cSBGb3vsZb)
- [r/CausalInference](https://reddit.com/r/causalinference)
- [Online Causal Inference Seminar](https://sites.google.com/view/ocis/)

### Code Snippet Library

```python
# Quick-start templates for common tasks

# 1. Propensity Score Matching Template
def ps_matching_pipeline(data, treatment, outcome, covariates):
    from sklearn.linear_model import LogisticRegression
    from sklearn.neighbors import NearestNeighbors

    # Estimate propensity scores
    ps_model = LogisticRegression()
    ps_model.fit(data[covariates], data[treatment])
    ps = ps_model.predict_proba(data[covariates])[:, 1]

    # Check overlap
    check_overlap(ps, data[treatment])

    # Match
    treated_ps = ps[data[treatment] == 1]
    control_ps = ps[data[treatment] == 0]

    matcher = NearestNeighbors(n_neighbors=1)
    matcher.fit(control_ps.reshape(-1, 1))
    distances, indices = matcher.kneighbors(treated_ps.reshape(-1, 1))

    # Estimate effect
    treated_outcomes = data[data[treatment] == 1][outcome]
    matched_control_outcomes = data[data[treatment] == 0].iloc[indices.flatten()][outcome]

    ate = (treated_outcomes - matched_control_outcomes).mean()
    return ate

# 2. DiD Template
def difference_in_differences(data, outcome, treatment, time, treated_group):
    import statsmodels.formula.api as smf

    # Create DiD interaction
    data['did'] = data[treated_group] * data[time]

    # Run regression
    formula = f'{outcome} ~ {treated_group} + {time} + did'
    model = smf.ols(formula, data=data).fit()

    # Extract treatment effect
    treatment_effect = model.params['did']
    confidence_interval = model.conf_int().loc['did']

    return {
        'effect': treatment_effect,
        'ci_lower': confidence_interval[0],
        'ci_upper': confidence_interval[1],
        'model': model
    }

# 3. Causal Forest Template
def causal_forest_analysis(X, Y, T, W):
    from econml.dml import CausalForestDML

    # Initialize and fit
    cf = CausalForestDML(
        model_y='auto',
        model_t='auto',
        discrete_treatment=True,
        n_estimators=100,
        min_samples_leaf=10
    )

    cf.fit(Y, T, X=X, W=W)

    # Get heterogeneous effects
    cate = cf.effect(X)
    cate_lb, cate_ub = cf.effect_interval(X)

    # Feature importance
    importance = cf.feature_importances_

    return {
        'cate': cate,
        'confidence_bounds': (cate_lb, cate_ub),
        'feature_importance': importance
    }
```

### Dataset Resources

#### Benchmark Datasets

1. **LaLonde (1986)** - Job training program
2. **IHDP** - Infant health and development
3. **ACIC 2016-2019** - Competition datasets
4. **Twins** - Twin births and mortality
5. **JOBS** - Job search intervention

#### Where to Find

- [Causal Inference Datasets](https://github.com/amit-sharma/causal-inference-datasets)
- [Vanderbilt Biostatistics Datasets](http://biostat.mc.vanderbilt.edu/wiki/Main/DataSets)
- [Harvard Dataverse](https://dataverse.harvard.edu/)

---

## ðŸŽ“ Certification & Recognition

### Building Your Credentials

#### Online Certificates

1. **Coursera** - Penn's Causal Inference Course
2. **EdX** - Harvard's Causal Diagrams
3. **Udacity** - Causal Inference Nanodegree

#### Portfolio Pieces

1. **GitHub Repository**

   - Clean, documented code
   - Multiple methods implemented
   - Real-world applications

2. **Technical Blog Posts**

   - Method explanations
   - Case studies
   - Tutorials

3. **Kaggle Notebooks**
   - Public analyses
   - Competition entries
   - Upvoted contributions

#### Community Involvement

- Answer Stack Overflow questions
- Contribute to PyWhy ecosystem
- Present at local meetups
- Publish on arXiv

---

## ðŸš€ After the 12 Weeks

### Immediate Next Steps

1. **Week 13-14: Integration**

   - Review all notes
   - Refactor code library
   - Polish portfolio projects

2. **Week 15-16: Specialization**

   - Choose focus area
   - Deep dive into advanced topic
   - Read recent papers

3. **Month 4+: Application**
   - Apply at work
   - Freelance projects
   - Research collaboration
   - Open source contribution

### Long-term Learning Path

#### 6 Months

- Master one specialized area
- Publish first blog post
- Complete significant project
- Join research reading group

#### 1 Year

- Conference presentation
- Contribute to major library
- Mentor others starting
- Industry application

#### 2+ Years

- Research publication
- Package development
- Thought leadership
- Teaching/training

### Staying Current

#### Weekly Habits

- Read 1 new paper
- Code 1 new technique
- Answer 1 community question

#### Monthly Goals

- Complete mini-project
- Write blog post
- Attend virtual seminar

#### Annual Objectives

- Attend conference
- Major contribution
- Expand network

---

## ðŸ’­ Final Thoughts

### Remember These Truths

1. **Causality is Hard** - Even experts disagree. Embrace uncertainty.

2. **Theory + Practice** - Neither alone is sufficient. Balance both.

3. **Domain Knowledge Matters** - Causal inference isn't just statistics.

4. **Start Simple** - Master basics before advanced methods.

5. **Community Helps** - Don't learn in isolation.

6. **Apply Early** - Look for causal questions everywhere.

7. **Document Everything** - Your future self will thank you.

8. **Confusion is Normal** - It means you're learning.

9. **Quality > Quantity** - Deep understanding beats surface knowledge.

10. **It's a Journey** - Causal thinking changes how you see the world.

---

## ðŸ“Œ Quick Start Checklist

**Right Now (10 minutes):**

- [ ] Create learning folder structure
- [ ] Install Python and Jupyter
- [ ] Join PyWhy Discord
- [ ] Bookmark this guide
- [ ] Schedule first 2-hour block

**Today:**

- [ ] Install core libraries
- [ ] Download first dataset
- [ ] Read Day 1 materials
- [ ] Write learning goals

**This Week:**

- [ ] Complete Days 1-6
- [ ] Join one community
- [ ] Find accountability partner
- [ ] Share learning publicly

---

**Your causal inference journey starts now. Block 2 hours tomorrow and begin with Day 1.**

_Remember: Every expert was once a beginner who didn't give up._

---

**Version:** 2.0  
**Last Updated:** November 2024  
**Feedback:** Welcome via GitHub issues  
**License:** CC BY-SA 4.0

---

_"Correlation does not imply causation, but it does waggle its eyebrows suggestively and gesture furtively while mouthing 'look over there'."_ - Randall Munroe, xkcd
